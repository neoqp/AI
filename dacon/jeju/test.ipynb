{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     TG\n",
      "1     TG\n",
      "2     TG\n",
      "3     TG\n",
      "4     TG\n",
      "5     TG\n",
      "6     TG\n",
      "7     TG\n",
      "8     TG\n",
      "9     TG\n",
      "10    TG\n",
      "Name: item, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = TabularDataset('train.csv')\n",
    "test = TabularDataset('test.csv')\n",
    "train = train.drop(['supply(kg)'], axis=1)\n",
    "\n",
    "print(train.loc[:10, \"item\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: train.csv | Columns = 7 / 7 | Rows = 59397 -> 59397\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231102_144350/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231102_144350/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Jan 27 02:56:13 UTC 2023\n",
      "Disk Space Avail:   982.15 GB / 1081.10 GB (90.8%)\n",
      "Train Data Rows:    49397\n",
      "Train Data Columns: 5\n",
      "Label Column: price(원/kg)\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (12333.0, 0.0, 685.05788, 1436.19226)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1789.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 15.51 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])                     : 3 | ['item', 'corporation', 'location']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['timestamp']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 2 | ['item', 'corporation']\n",
      "\t\t('int', ['bool'])            : 1 | ['location']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['timestamp', 'timestamp.year', 'timestamp.month', 'timestamp.day', 'timestamp.dayofweek']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.12 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.05061036095309432, Train Rows: 46897, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1503.5851\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1503.5851\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 757.581\n",
      "[2000]\tvalid_set's rmse: 754.223\n",
      "[3000]\tvalid_set's rmse: 753.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-752.6658\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 619.787\n",
      "[2000]\tvalid_set's rmse: 612.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-611.4142\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 187 due to low memory. Expected memory usage reduced from 23.98% -> 15.0% of available memory...\n",
      "\t-623.2077\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-649.3385\t = Validation score   (-root_mean_squared_error)\n",
      "\t51.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 167 due to low memory. Expected memory usage reduced from 26.83% -> 15.0% of available memory...\n",
      "\t-631.8134\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-674.3194\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-629.7095\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-884.158\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-615.4331\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-592.3647\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 114.37s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231102_144350/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         -18.476772\n",
      "1        -124.749802\n",
      "2        1291.468628\n",
      "3        1427.944214\n",
      "4        1560.883057\n",
      "            ...     \n",
      "9996     7375.592285\n",
      "9997      456.918488\n",
      "9998     7812.675781\n",
      "9999     9077.771484\n",
      "10000    9324.866211\n",
      "Name: price(원/kg), Length: 10001, dtype: float32\n",
      "0            0.0\n",
      "1            0.0\n",
      "2         1728.0\n",
      "3         1408.0\n",
      "4         1250.0\n",
      "          ...   \n",
      "9996     11667.0\n",
      "9997         0.0\n",
      "9998     12000.0\n",
      "9999     11107.0\n",
      "10000     9904.0\n",
      "Name: price(원/kg), Length: 10001, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -2017.213836752671\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -2017.213836752671,\n",
      "    \"mean_squared_error\": -4069151.663186432,\n",
      "    \"mean_absolute_error\": -1191.243437388619,\n",
      "    \"r2\": 0.5177200319330157,\n",
      "    \"pearsonr\": 0.7393301503984804,\n",
      "    \"median_absolute_error\": -497.38525390625\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_mean_squared_error': -2017.213836752671, 'mean_squared_error': -4069151.663186432, 'mean_absolute_error': -1191.243437388619, 'r2': 0.5177200319330157, 'pearsonr': 0.7393301503984804, 'median_absolute_error': -497.38525390625}\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "base = TabularDataset('train.csv')\n",
    "base = base.drop(['supply(kg)'], axis=1)\n",
    "train = base[10000:]\n",
    "test = base.loc[:10000]\n",
    "\n",
    "predictor = TabularPredictor(label='price(원/kg)').fit(train_data=train)\n",
    "y_pred = predictor.predict(test)\n",
    "\n",
    "print(y_pred)\n",
    "print(test['price(원/kg)'])\n",
    "result = predictor.evaluate(test)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      location corporation            timestamp  timestamp.year  \\\n",
      "9394         0           3  1568419200000000000            2019   \n",
      "898          0           0  1623888000000000000            2021   \n",
      "2398         1           0  1621900800000000000            2021   \n",
      "5906         1           1  1661817600000000000            2022   \n",
      "2343         1           0  1617148800000000000            2021   \n",
      "...        ...         ...                  ...             ...   \n",
      "9319         0           3  1561939200000000000            2019   \n",
      "2662         1           0  1644710400000000000            2022   \n",
      "6925         0           2  1618272000000000000            2021   \n",
      "8070         1           2  1585612800000000000            2020   \n",
      "3651         0           1  1598572800000000000            2020   \n",
      "\n",
      "      timestamp.month  timestamp.day  timestamp.dayofweek  \n",
      "9394                9             14                    5  \n",
      "898                 6             17                    3  \n",
      "2398                5             25                    1  \n",
      "5906                8             30                    1  \n",
      "2343                3             31                    2  \n",
      "...               ...            ...                  ...  \n",
      "9319                7              1                    0  \n",
      "2662                2             13                    6  \n",
      "6925                4             13                    1  \n",
      "8070                3             31                    1  \n",
      "3651                8             28                    4  \n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "dir = 'AutogluonModels/ag-20231102_134319/utils/data/'\n",
    "with open(dir + 'X_val.pkl', 'rb') as f:\n",
    "    file = pickle.load(f)\n",
    "    print(file)\n",
    "\n",
    "print()\n",
    "with open(dir + 'y.pkl', 'rb') as f:\n",
    "    file = pickle.load(f)\n",
    "    print(len(file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
